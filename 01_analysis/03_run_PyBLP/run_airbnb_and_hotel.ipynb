{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pyblp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re \n",
    "pyblp.options.verbose = True\n",
    "\n",
    "\n",
    "path = os.path.join('..', '..', '00_build', 'output', 'df_all.csv')\n",
    "product_data = pd.read_csv(path)\n",
    "\n",
    "X1_formulation  = pyblp.Formulation(\n",
    "    # '0 + num_of_beds + is_airbnb',\n",
    "    '0 + prices + cleanness_score + location + staff_communication_score + room_score + num_of_beds + num_of_reviews + is_airbnb',\n",
    "    # '0 + prices + cleanness_score + location + staff_communication_score + room_score + num_of_beds + num_of_reviews + is_airbnb',\n",
    "    # '0 + prices + cleanness_score + location + staff_communication_score + room_score + num_of_beds + num_of_reviews',\n",
    "    absorb = 'C(city_ids) + C(day_of_week) + C(month)'\n",
    ")\n",
    "\n",
    "# X2_formulation= pyblp.Formulation('0 + prices + num_of_reviews')\n",
    "X2_formulation= pyblp.Formulation('0 + prices')\n",
    "# 2_formulation= pyblp.Formulation('0 + prices + room_score + cleanness_score + location + staff_communication_score')\n",
    "\n",
    "\n",
    "product_formulations_X1_and_X2 = (X1_formulation, X2_formulation)\n",
    "\n",
    "IVs = pyblp.build_differentiation_instruments(\n",
    "    pyblp.Formulation(\n",
    "        '0 + cleanness_score + location + staff_communication_score + room_score + num_of_beds + num_of_reviews'\n",
    "        ),\n",
    "    product_data,\n",
    "    version = 'quadratic',\n",
    "    interact = True\n",
    ")\n",
    "\n",
    "for i, column in enumerate(IVs.T):\n",
    "    product_data[f'demand_instruments{i}'] = column\n",
    "\n",
    "\n",
    "\n",
    "mc_integration = pyblp.Integration('monte_carlo', size=200, specification_options={'seed': 0})\n",
    "# mc_integration = pyblp.Integration('monte_carlo', size=100, specification_options={'seed': 0})\n",
    "\n",
    "mc_problem_X1_and_X2 = pyblp.Problem(product_formulations_X1_and_X2, product_data, integration = mc_integration)\n",
    "# mc_problem_X1 = pyblp.Problem(X1_formulation, product_data)\n",
    "\n",
    "bfgs = pyblp.Optimization('bfgs', {'gtol': 1e-8})\n",
    "# bfgs = pyblp.Optimization('l-bfgs-b', {'gtol': 1e-8})\n",
    "\n",
    "\n",
    "# lower = np.diag([None, None, None, None, None])\n",
    "lower = np.diag([None, None])\n",
    "# upper = np.diag([-0.01, None, None, None, None])\n",
    "upper = np.diag([None, None])\n",
    "initial_sigma = np.diag([-10, 5, 5, 5, 5])\n",
    "\n",
    "\n",
    "# 列名のリストから\" demand_instrument\"に該当するものを抽出\n",
    "instrument_columns = [col for col in product_data.columns if col.startswith('demand_instrument')]\n",
    "\n",
    "# 各列名の数字部分を抽出して最大値を見つける\n",
    "max_instrument_num = max([int(re.search(r'\\d+', col).group()) for col in instrument_columns])\n",
    "\n",
    "# 新しい変数名を作成\n",
    "new_instrument_col = f'demand_instrument{max_instrument_num+1}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_for_ownership_matrix = product_data.copy()\n",
    "df_for_ownership_matrix = df_for_ownership_matrix.drop(columns=['firm_ids'])\n",
    "df_for_ownership_matrix = df_for_ownership_matrix.rename(columns={'merger_ids': 'firm_ids'})\n",
    "\n",
    "def get_room_type_for_firm_id(x):\n",
    "    # firm_ids が 'X' の行をフィルタして、room_type の値を取得\n",
    "    room_type_value = df_for_ownership_matrix[df_for_ownership_matrix['firm_ids'] == x]['room_type'].values\n",
    "    return room_type_value[0] if len(room_type_value) > 0 else None\n",
    "\n",
    "def kappa_specification(f, g):\n",
    "    # f, gはfirm_idsの値を受け取るらしい。\n",
    "    # print(\"f = \", f)\n",
    "    # print(\"g = \", g)\n",
    "    \n",
    "    if f == g:\n",
    "       return 1\n",
    "    if f == 'Airbnb' and get_room_type_for_firm_id(g) == 'Airbnb':\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "ownership_matrix = pyblp.build_ownership(df_for_ownership_matrix, kappa_specification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################\n",
    "# BLP Estimation by PyBLP\n",
    "##########################################################\n",
    "\n",
    "##########################################################\n",
    "# Random Coefficient Nested Logit Model\n",
    "##########################################################\n",
    "def solve_nl(df):\n",
    "    groups = df.groupby(['market_ids', 'nesting_ids'])\n",
    "    df[new_instrument_col] = groups['shares'].transform(np.size)\n",
    "    \n",
    "    problem = pyblp.Problem(product_formulations_X1_and_X2, df, integration = mc_integration)\n",
    "    # problem = pyblp.Problem(X1_formulation, df)\n",
    "    \n",
    "    return problem.solve(\n",
    "        rho = 0.7,\n",
    "        sigma=np.diag([-5]),\n",
    "        sigma_bounds= (None, None),\n",
    "        # sigma_bounds= (lower, upper),\n",
    "        W_type='clustered',\n",
    "        se_type='clustered'\n",
    "        )\n",
    "\n",
    "results = solve_nl(product_data)\n",
    "\n",
    "##########################################################\n",
    "# Random Coefficient Logit Model\n",
    "##########################################################\n",
    "# with pyblp.parallel(2):\n",
    "#     results = mc_problem_X1_and_X2.solve(\n",
    "#         sigma=np.diag([-20]),\n",
    "#         # sigma=initial_sigma,\n",
    "#         #sigma_bounds= (lower, upper),\n",
    "#         sigma_bounds= (None, None),\n",
    "#         optimization=bfgs,\n",
    "#         # W_type='clustered',\n",
    "#         # se_type='clustered',\n",
    "#         )\n",
    "    # Plain Logit Model\n",
    "    # results = mc_problem_X1.solve(optimization=bfgs, se_type='clustered')\n",
    "\n",
    "\n",
    "#############################\n",
    "# Post Estimatinon Analysis\n",
    "#############################\n",
    "\n",
    "with pyblp.parallel(2):\n",
    "    # Marginal Costs\n",
    "    costs = results.compute_costs()\n",
    "\n",
    "    # HHI, Profits, Consumer Surplus, Markups\n",
    "    hhi = results.compute_hhi()\n",
    "    profits = results.compute_profits(costs=costs)\n",
    "    cs = results.compute_consumer_surpluses()\n",
    "    markups = results.compute_markups(costs=costs)\n",
    "\n",
    "    elasticities = results.compute_elasticities()\n",
    "    diversions = results.compute_diversion_ratios()\n",
    "\n",
    "    means = results.extract_diagonal_means(elasticities)\n",
    "    aggregates = results.compute_aggregate_elasticities(factor=0.1)\n",
    "\n",
    "    # product_dataのmerger_ids列がAirbnbの場合、costsの対応する要素を0に設定\n",
    "    mask = product_data['merger_ids'] == 'Airbnb'\n",
    "    new_costs = costs.copy()  # costsをコピーして新しい変数new_costsを作成\n",
    "    new_costs[mask] = 0  # Airbnbに該当する部分だけnew_costsを変更\n",
    "    \n",
    "    # Counterfactuals\n",
    "    changed_prices = results.compute_prices(\n",
    "        firm_ids = product_data['merger_ids'],\n",
    "        ownership = ownership_matrix,\n",
    "        # costs=new_costs  # new_costsを使用\n",
    "        costs = costs\n",
    "    )\n",
    "\n",
    "    changed_shares = results.compute_shares(changed_prices)\n",
    "    changed_profits = results.compute_profits(changed_prices, changed_shares, costs) \n",
    "    # changed_profits = results.compute_profits(changed_prices, changed_shares, new_costs) \n",
    "    changed_cs = results.compute_consumer_surpluses(changed_prices)\n",
    "    changed_markups = results.compute_markups(changed_prices, costs)\n",
    "    # changed_markups = results.compute_markups(changed_prices, new_costs)\n",
    "    changed_hhi = results.compute_hhi(shares=changed_shares)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (changed_cs - cs) / cs の計算\n",
    "relative_change = (changed_cs - cs) / cs * 100\n",
    "\n",
    "# 必要な統計量を計算\n",
    "mean_value = np.mean(relative_change)\n",
    "min_value = np.min(relative_change)\n",
    "max_value = np.max(relative_change)\n",
    "median_value = np.median(relative_change)\n",
    "std_value = np.std(relative_change)\n",
    "# ユニークな値を取得\n",
    "unique_values = np.unique(relative_change)\n",
    "\n",
    "# 結果を表示\n",
    "# print(\"Unique values:\")\n",
    "# print(unique_values)\n",
    "# 結果を表示\n",
    "print(f\"Mean: {mean_value}\")\n",
    "print(f\"Median: {median_value}\")\n",
    "print(f\"Min: {min_value}\")\n",
    "print(f\"Max: {max_value}\")\n",
    "print(f\"Standard Deviation: {std_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relative_change_profits = (changed_profits - profits) / profits * 100\n",
    "\n",
    "# 必要な統計量を計算\n",
    "mean_value_profits = np.mean(relative_change_profits)\n",
    "min_value_profits = np.min(relative_change_profits)\n",
    "max_value_profits = np.max(relative_change_profits)\n",
    "median_value_profits = np.median(relative_change_profits)\n",
    "std_value_profits = np.std(relative_change_profits)\n",
    "\n",
    "# 結果を表示\n",
    "print(f\"Mean: {mean_value_profits}\")\n",
    "print(f\"Median: {median_value_profits}\")\n",
    "print(f\"Min: {min_value_profits}\")\n",
    "print(f\"Max: {max_value_profits}\")\n",
    "print(f\"Standard Deviation: {std_value_profits}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(changed_markups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 配列のリスト\n",
    "arrays_to_add = {\n",
    "    'costs': costs,\n",
    "    'mergered_costs': new_costs,\n",
    "    # 'hhi': hhi,\n",
    "    'profits': profits,\n",
    "    'changed_profits': changed_profits,\n",
    "    # 'cs': cs,\n",
    "    'markups': markups,\n",
    "    'changed_markups': changed_markups,\n",
    "    # 'elasticities': elasticities,\n",
    "    # 'diversions': diversions,\n",
    "    # 'means': means,\n",
    "    # 'aggregates': aggregates,\n",
    "    'changed_prices': changed_prices,\n",
    "    'changed_shares': changed_shares,\n",
    "    # 'changed_cs': changed_cs\n",
    "    'delta': results.delta,\n",
    "    'xi_fe': results.xi_fe,\n",
    "    'xi': results.xi,\n",
    "}\n",
    "\n",
    "# product_dataに各配列を新しい列として追加\n",
    "for name, array in arrays_to_add.items():\n",
    "    # 配列を1次元に変換（必要であれば）\n",
    "    array = array.flatten() if array.ndim > 1 else array\n",
    "    product_data[name] = array\n",
    "\n",
    "# market_ids に対応する cs と changed_cs の辞書をそれぞれ作成\n",
    "market_ids_unique = product_data['market_ids'].unique()\n",
    "\n",
    "cs_dict = dict(zip(market_ids_unique, cs))\n",
    "changed_cs_dict = dict(zip(market_ids_unique, changed_cs))\n",
    "hhi_dict = dict(zip(market_ids_unique, hhi))\n",
    "changed_hhi_dict = dict(zip(market_ids_unique, changed_hhi))\n",
    "changed_shares_dict = dict(zip(market_ids_unique, changed_shares))\n",
    "means_elasticities_dict = dict(zip(market_ids_unique, means))\n",
    "aggregates_elasticities_dict = dict(zip(market_ids_unique, aggregates))\n",
    "\n",
    "# map() を使って、それぞれの列に値を割り当て\n",
    "product_data['cs'] = product_data['market_ids'].map(cs_dict)\n",
    "product_data['changed_cs'] = product_data['market_ids'].map(changed_cs_dict)\n",
    "product_data['hhi'] = product_data['market_ids'].map(hhi_dict)\n",
    "product_data['changed_hhi'] = product_data['market_ids'].map(changed_hhi_dict)\n",
    "product_data['changed_shares'] = product_data['market_ids'].map(changed_shares_dict)\n",
    "product_data['means_elasticities'] = product_data['market_ids'].map(means_elasticities_dict)\n",
    "product_data['aggregates_elasticities'] = product_data['market_ids'].map(aggregates_elasticities_dict)\n",
    "\n",
    "# path = \"/Users/hanazawakaede/Library/CloudStorage/Dropbox/02_Projects/Airbnb/01_analysis/05_output_all/product_data_plain_logit.csv\"\n",
    "# path = \"/Users/hanazawakaede/Library/CloudStorage/Dropbox/02_Projects/Airbnb/01_analysis/05_output_all/product_data_random_coefficient_logit.csv\"\n",
    "# path = \"/Users/hanazawakaede/Library/CloudStorage/Dropbox/02_Projects/Airbnb/01_analysis/05_output_all/product_data_nested_logit.csv\"\n",
    "path = \"/Users/hanazawakaede/Library/CloudStorage/Dropbox/02_Projects/Airbnb/01_analysis/05_output_all/product_data_random_coefficient_nested_logit.csv\"\n",
    "\n",
    "# product_dataを指定されたパスに書き出し\n",
    "product_data.to_csv(path, index=False)\n",
    "\n",
    "# # changed_profitsとhhiをDataFrameに変換\n",
    "# output_df = pd.DataFrame({\n",
    "#     'changed_profits': changed_profits.flatten(),\n",
    "# })\n",
    "\n",
    "# # 指定されたパスに書き出し\n",
    "# output_path = \"/Users/hanazawakaede/Library/CloudStorage/Dropbox/02_Projects/Airbnb/01_analysis/05_output_all/changed_profit.csv\"\n",
    "# output_df.to_csv(output_path, index=False)\n",
    "\n",
    "# # changed_profitsとhhiをDataFrameに変換\n",
    "# output_df = pd.DataFrame({\n",
    "#     'changed_markups': changed_markups.flatten(),\n",
    "# })\n",
    "\n",
    "# # 指定されたパスに書き出し\n",
    "# output_path = \"/Users/hanazawakaede/Library/CloudStorage/Dropbox/02_Projects/Airbnb/01_analysis/05_output_all/changed_markups.csv\"\n",
    "# output_df.to_csv(output_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bootstrapped_results = results.bootstrap(draws=1000, seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# パラメータ名のリスト\n",
    "param_names = [\"prices\", \"room_score\", \"cleanness_score\", \"location\", \"staff_communication_score\", \n",
    "               # \"is_airbnb\",\n",
    "               \"num_of_reviews\",\n",
    "                \"num_of_beds\"]\n",
    "\n",
    "# データフレームを保存するためのリスト\n",
    "dataframes = []\n",
    "\n",
    "# 各パラメータに対する信頼区間の計算\n",
    "for i, param_name in enumerate(param_names):\n",
    "    params = bootstrapped_results.bootstrapped_beta[:, i, 0]\n",
    "    \n",
    "    # 各信頼区間を計算し、文字列形式に変換\n",
    "    lower_90, upper_90 = np.percentile(params, [5, 95])\n",
    "    lower_95, upper_95 = np.percentile(params, [2.5, 97.5])\n",
    "    lower_99, upper_99 = np.percentile(params, [0.5, 99.5])\n",
    "    \n",
    "    ci_90 = f\"[{lower_90:.6f}, {upper_90:.6f}]\"\n",
    "    ci_95 = f\"[{lower_95:.6f}, {upper_95:.6f}]\"\n",
    "    ci_99 = f\"[{lower_99:.6f}, {upper_99:.6f}]\"\n",
    "    \n",
    "    # データフレームとして保存\n",
    "    df = pd.DataFrame({\n",
    "        \"param_value\": params,\n",
    "        \"param\": param_name,\n",
    "        \"CI_90\": ci_90,\n",
    "        \"CI_95\": ci_95,\n",
    "        \"CI_99\": ci_99\n",
    "    })\n",
    "    \n",
    "    # リストに追加\n",
    "    dataframes.append(df)\n",
    "\n",
    "\n",
    "\n",
    "rho_params = bootstrapped_results.bootstrapped_rho.reshape(-1)\n",
    "lower_90, upper_90 = np.percentile(rho_params, [5, 95])\n",
    "lower_95, upper_95 = np.percentile(rho_params, [2.5, 97.5])\n",
    "lower_99, upper_99 = np.percentile(rho_params, [0.5, 99.5])\n",
    "\n",
    "ci_90 = f\"[{lower_90:.6f}, {upper_90:.6f}]\"\n",
    "ci_95 = f\"[{lower_95:.6f}, {upper_95:.6f}]\"\n",
    "ci_99 = f\"[{lower_99:.6f}, {upper_99:.6f}]\"\n",
    "\n",
    "# rho データフレームを作成\n",
    "sigma_df = pd.DataFrame({\n",
    "    \"param_value\": rho_params,\n",
    "    'param': 'rho',\n",
    "    \"CI_90\": ci_90,\n",
    "    \"CI_95\": ci_95,\n",
    "    \"CI_99\": ci_99\n",
    "})\n",
    "# rhoをリストに追加\n",
    "dataframes.append(sigma_df)\n",
    "\n",
    "# sigma の処理\n",
    "# sigma_params = bootstrapped_results.bootstrapped_sigma.reshape(-1)\n",
    "# lower_90, upper_90 = np.percentile(sigma_params, [5, 95])\n",
    "# lower_95, upper_95 = np.percentile(sigma_params, [2.5, 97.5])\n",
    "# lower_99, upper_99 = np.percentile(sigma_params, [0.5, 99.5])\n",
    "\n",
    "# ci_90 = f\"[{lower_90:.6f}, {upper_90:.6f}]\"\n",
    "# ci_95 = f\"[{lower_95:.6f}, {upper_95:.6f}]\"\n",
    "# ci_99 = f\"[{lower_99:.6f}, {upper_99:.6f}]\"\n",
    "\n",
    "# # sigma データフレームを作成\n",
    "# sigma_df = pd.DataFrame({\n",
    "#     \"param_value\": sigma_params,\n",
    "#     \"param\": \"sigma\",\n",
    "#     \"CI_90\": ci_90,\n",
    "#     \"CI_95\": ci_95,\n",
    "#     \"CI_99\": ci_99\n",
    "# })\n",
    "\n",
    "# # sigmaをリストに追加\n",
    "# dataframes.append(sigma_df)\n",
    "\n",
    "# 全てのデータフレームを連結して1つのデータフレームにする\n",
    "all_params_df = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "# 結果を確認する\n",
    "\n",
    "\n",
    "# CSVファイルとして指定したパスに書き出し\n",
    "output_path = \"/Users/hanazawakaede/Library/CloudStorage/Dropbox/02_Projects/Airbnb/01_analysis/05_output_all/params_output_Nested_Logit.csv\"\n",
    "all_params_df.to_csv(output_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bootstrapped_results.bootstrapped_rho.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "changed_prices_flat = changed_prices.flatten()\n",
    "price_difference = changed_prices_flat - product_data['prices'].values\n",
    "plt.hist(price_difference)\n",
    "plt.xlabel('Price Difference')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(costs);\n",
    "plt.legend([\"Marginal Costs\"]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_market = product_data['market_ids'] == '2024-03-09:ota:5'\n",
    "plt.colorbar(plt.matshow(elasticities[single_market]));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.colorbar(plt.matshow(diversions[single_market]));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(\n",
    "    [means.flatten(), aggregates.flatten()],\n",
    "    color=['red', 'blue'],\n",
    "    bins=50\n",
    ");\n",
    "plt.legend(['Mean Own Elasticities', 'Aggregate Elasticities']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(markups);\n",
    "plt.legend([\"Markups\"]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(changed_profits - profits);\n",
    "# plt.xlim(-50, 50)\n",
    "plt.legend([\"Profit Changes\"]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist((changed_cs - cs)/ cs);\n",
    "plt.legend([\"CS Changes\"]);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Airbnb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
